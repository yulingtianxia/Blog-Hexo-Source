---
title: Implementing CNN with MPS
date: 2017-05-30 17:20:32
tags:
- Machine Leaning
- iOS
- Metal
---

æœ€è¿‘ä¸€ä¸ªæœˆä»é›¶å¼€å§‹è‡ªå­¦äº†ä¸‹æœ‰å…³ iOS ä¸Šçš„æœºå™¨å­¦ä¹ ç›¸å…³çŸ¥è¯†ï¼Œäº²èº«å®è·µäº†ä»æ•°æ®é‡‡é›†åˆ°è®­ç»ƒæ¨¡å‹å†åˆ°ç§»åŠ¨ç«¯é¢„æµ‹çš„æµç¨‹ã€‚ç†è®ºçŸ¥è¯†å­¦ä¹ è·¯å¾„ä¸ºï¼š**æœºå™¨å­¦ä¹ ->æ·±åº¦å­¦ä¹ ->è¿ç§»å­¦ä¹ **ï¼›å®è·µæ¡†æ¶å­¦ä¹ è·¯å¾„ä¸ºï¼š**TensorFlow->Keras->MPS(iOS 10)**ã€‚æœ€ç»ˆå®Œæˆä¸€ä¸ªç®€å•çš„æ‰‹åŠ¿å›¾åƒäº”åˆ†ç±»é—®é¢˜ï¼Œå¹¶é¢„æµ‹ iOS æ‘„åƒå¤´é‡‡é›†çš„å›¾ç‰‡ã€‚æœ€ç»ˆç»“æœï¼Œè®­ç»ƒé›†å‡†ç¡®ç‡ 96.26%ï¼Œäº¤å‰éªŒè¯é›†å‡†ç¡®ç‡ 73.86%ã€‚

<!-- more -->

## ç†è®ºåŸºç¡€

è™½ç„¶ç»“æœå¯¼å‘å¾ˆé‡è¦ï¼Œä½†æ˜¯æˆ‘è¿˜æ˜¯æƒ³ä»åŸºç¡€å­¦èµ·ï¼Œè€Œä¸æ˜¯å»æ€¥äºå»ç½‘ä¸Šæ‰¾ç°æˆçš„è§£å†³æ–¹æ¡ˆæ¥è°ƒå‚ã€‚æ¯•ç«Ÿæˆ‘çš„ç›®çš„æ˜¯æ‹“å®½çŸ¥è¯†é¢ï¼Œå¼€æ–°çš„æŠ€èƒ½æ ‘ã€‚

ç¬¬ä¸€å‘¨ä»é›¶å¼€å§‹å­¦ä¹ äº† Coursera ä¸Š Stanford Ng æ•™æˆçš„ [Machine Learning](https://www.coursera.org/learn/machine-learning/home) ç»å…¸è¯¾ç¨‹ï¼Œç”¨ Matlab ç¼–å†™äº†ä¸€äº› Demoï¼Œç”¨ä¸€å‘¨æ—¶é—´å®Œæˆäº†åŸæœ¬éœ€è¦ 11 å‘¨æ—¶é—´çš„æ‰€æœ‰è¯¾ç¨‹å’Œè€ƒè¯•ï¼Œå¯¹æœºå™¨å­¦ä¹ çš„åŸºç¡€çŸ¥è¯†æœ‰äº†æŒæ¡ã€‚

![](http://wx3.sinaimg.cn/mw1024/642c5793ly1ff5ornniluj21kw0u3tn2.jpg)

æœºå™¨å­¦ä¹ å¤§ä½“å¯ä»¥åˆ†ä¸ºæœ‰ç›‘ç£å­¦ä¹ å’Œæ— ç›‘ç£å­¦ä¹ ã€‚å¸¦æ ‡ç­¾æ•°æ®çš„æœ‰ç›‘ç£å­¦ä¹ åŒ…å«ä»æœ€ç®€å•çš„çº¿æ€§å›å½’åˆ°é€»è¾‘å›å½’ï¼Œå†åˆ°ç¥ç»ç½‘ç»œå’Œ SVMï¼ˆæ”¯æŒå‘é‡æœºï¼‰ã€‚æ— ç›‘ç£å­¦ä¹ åŒ…å«å¤§å­¦ç«–ç›´çš„ K-means èšç±»ï¼ŒPCA(Principal Components Analysis) é™ç»´ã€‚ä»¥åŠå¸¦æ ‡ç­¾æ•°æ®çš„å¼‚å¸¸æ£€æµ‹ç®—æ³•ã€‚ä¸ºäº†ç¡®ä¿æœºå™¨å­¦ä¹ çš„æ•ˆæœï¼Œéœ€è¦é€šè¿‡çœ‹æ‡‚å­¦ä¹ æ›²çº¿å†³å®šä¸‹ä¸€æ­¥çš„å·¥ä½œï¼Œæ˜¯è§£å†³ overfit è¿˜æ˜¯ underfitã€‚ä½¿ç”¨äº¤å‰éªŒè¯é›†å’Œæµ‹è¯•é›†è¯„ä¼°æ¨¡å‹æ—¶ï¼Œå¦‚ä½•å¹³è¡¡å‡†ç¡®ç‡å’Œå¬å›ç‡ï¼Œæ¯”å¦‚ F1 Score æŒ‡æ ‡ã€‚åœ¨æ•°æ®é¢„å¤„ç†ä¸Šè¦äº†è§£ä¸€äº›æ•°æ®å½’ä¸€åŒ–æ ‡å‡†åŒ–çš„æ–¹æ³•ã€‚

å…‰æŒæ¡æœºå™¨å­¦ä¹ çš„åŸºç¡€çŸ¥è¯†æ˜¾ç„¶ä¸å¤Ÿï¼Œå¤§è€Œå…¨ä¸å¦‚ä¸“è€Œç²¾ã€‚æ·±åº¦å­¦ä¹ åœ¨å›¾åƒè¯†åˆ«é¢†åŸŸå¤§æ”¾å¼‚å½©ï¼Œå…¶å®æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œè€Œæ·±åº¦å­¦ä¹ é¢†åŸŸæœ€è¿‘åœ¨å›¾åƒè¯†åˆ«ä¸Šåº”ç”¨æœ€ç«çš„å¯èƒ½å°±æ˜¯ CNN äº†ã€‚æ‰€ä»¥åœ¨ç‹‚å­¦æ·±åº¦å­¦ä¹ çš„æ—¶å€™é‡ç‚¹ç ”ç©¶äº†ä¸‹ CNNã€‚

### å·ç§¯ç¥ç»ç½‘ç»œç®€ä»‹

å…¨è¿æ¥ç½‘ç»œæƒé‡è¿‡å¤šï¼Œè€Œå·ç§¯ç¥ç»ç½‘ç»œå¯ä»¥å®ç°æƒå€¼å…±äº«ï¼Œå¼•å…¥äº†æ·±åº¦ï¼Œæ•°æ®ä¸º 3D çš„ã€‚æ¨èæŸ¥çœ‹ Stanford çš„ [Convolutional Neural Networks (CNNs / ConvNets)](http://cs231n.github.io/convolutional-networks/)ï¼Œä¸­æ–‡ç¿»è¯‘ï¼š[CS231nè¯¾ç¨‹ç¬”è®°ç¿»è¯‘ï¼šå·ç§¯ç¥ç»ç½‘ç»œç¬”è®°](https://zhuanlan.zhihu.com/p/22038289)ã€‚

å·ç§¯æ ¸ä¸€èˆ¬ä¸ºå¥‡æ•°ï¼Œå¸¸ç”¨çš„éƒ½æ˜¯å°å·ç§¯æ ¸ï¼Œæ¯”å¦‚ 1x1,3x3,5x5ã€‚[å·ç§¯](https://zh.wikipedia.org/wiki/å·ç§¯)æ˜¯ä¸€ç§æ•°å­¦è¿ç®—ï¼Œå·ç§¯æ ¸åœ¨æ‰«ææ•°æ®çš„æ—¶å€™ï¼Œæ­£å¥½åšçš„å°±æ˜¯å·ç§¯è¿ç®—ã€‚å·ç§¯æ ¸å…¶å®å°±æ˜¯ä¸ªæ»¤æ³¢å™¨ï¼Œé€šè¿‡å¹³ç§»ç‚¹ç§¯è¿ç®—å¤„ç†æ•°æ®ã€‚ä¸€ä¸ªå·ç§¯å±‚å¯ä»¥æœ‰å¤šä¸ªå·ç§¯æ ¸ï¼Œä¹Ÿå°±æ˜¯å¤šä¸ªæ»¤æ³¢å™¨ï¼Œæ¯ç§æ»¤æ³¢å™¨æ‰€ã€æ„Ÿå—ã€çš„å†…å®¹ä¸åŒï¼Œç»“æœä¹Ÿå¾ˆæœ‰æ„æ€ã€‚å¯ä»¥çœ‹çœ‹è¿™ç¯‡æ–‡ç« ï¼š[How convolutional neural networks see the world](https://blog.keras.io/how-convolutional-neural-networks-see-the-world.html)ã€‚

CNN ä¸­ä¸ä»…æœ‰ Convolutionï¼Œè¿˜æœ‰ Poolingï¼ŒActivationï¼ŒFully Connectedç­‰å±‚çº§ã€‚

Pooling å°±æ˜¯ downsamplingï¼Œå‡å°æ•°æ®å°ºå¯¸ï¼Œå¸¸ç”¨çš„æœ‰æœ‰ maxï¼Œaverage ç­‰è¿ç®—ã€‚
Activation å°±æ˜¯æ¿€æ´»å‡½æ•°ï¼Œå¸¸ç”¨çš„æœ‰ sigmoidï¼ŒReLU ç­‰ã€‚
Fully Connected ä¹Ÿå« Denseï¼Œå› ä¸ºå…¨è¿æ¥æƒé‡å¯†åº¦å¾ˆå¤§ã€‚å…¶å®å°±æ˜¯ä¸ªå·ç§¯æ ¸å®½é«˜ç­‰äºè¾“å…¥æ•°æ®å®½é«˜çš„ç‰¹æ®Šå·ç§¯å±‚ã€‚å·ç§¯å±‚å’Œå…¨è¿æ¥å±‚å¯ä»¥ç­‰æ•ˆè½¬æ¢ã€‚

å¦‚æœå·ç§¯æ ¸å°ºå¯¸ä¸æ˜¯ 1x1ï¼Œæˆ–å¹³ç§»çš„æ­¥é•¿ä¸æ˜¯ 1x1ï¼Œé‚£ä¹ˆå·ç§¯è¿ç®—åçš„ç»“æœè‚¯å®šæ¯”åŸå°ºå¯¸è¦å°ï¼Œæ‰€ä»¥padding è§„åˆ™å°±å¾ˆé‡è¦ã€‚ä¸€èˆ¬å¸¸ç”¨çš„ã€Sameã€è§„åˆ™å°±æ˜¯åœ¨æ•°æ®å‘¨å›´å¡«å……ä¸€äº› 0ï¼Œä½¿å¾—å·ç§¯è¿ç®—åçš„æ•°æ®å®½å’Œé«˜è·Ÿè¾“å…¥æ•°æ®ä¸€æ ·ã€‚

### å›¾ç‰‡åˆ†ç±»å¸¸ç”¨çš„æ•°æ®å’Œé¢„è®¾ç½‘ç»œæ¨¡å‹

å›¾ç‰‡åˆ†ç±»ä½¿ç”¨å·²ç»æ‰“å¥½æ ‡ç­¾çš„æ•°æ®åº“æ¥è¿›è¡Œæœ‰ç›‘ç£å­¦ä¹ ï¼Œ

Dataset | Training Set Size | Testing Set Size | Number of Classes | Comments
:------:|:---------------:|:---------------------:|:-----------:|:-----------:
[Cifar10](https://www.cs.toronto.edu/~kriz/cifar.html) | 60k| 10k | 10 |32x32 color
[MNIST](http://yann.lecun.com/exdb/mnist/)| 60k | 10k | 10 | 28x28 gray
[ImageNet](http://www.image-net.org/challenges/LSVRC/2012/)|1.2M| 50k | 1000 | Various sizes

[MNIST](http://yann.lecun.com/exdb/mnist/) ç®—æ˜¯æ·±åº¦å­¦ä¹ é¢†åŸŸçš„ HelloWorld äº†ã€‚

[CIFAR](https://www.cs.toronto.edu/%7Ekriz/cifar.html) å°å°ºå¯¸å›¾ç‰‡æ•°æ®åº“ï¼ŒåŒ…å« CIFAR10 å’Œ CIFAR100ã€‚

åœ¨å›¾åƒè¯†åˆ«é¢†åŸŸï¼Œ[ImageNet](http://image-net.org) æ˜¯éå¸¸æœ‰åçš„æ•°æ®åº“ï¼Œå†å¹´æŒ‘æˆ˜ä¸­éƒ½æœ‰æ–°çš„æ›´å¤æ‚çš„ç¥ç»ç½‘ç»œè·‘å‡ºæ›´å¥½çš„ç»“æœã€‚ä¸‹é¢çš„è¡¨æ˜¯ä¸€äº›ç½‘ç»œæ¨¡å‹åœ¨ [ImageNet](http://image-net.org) Challenge ä¸­çš„å‡†ç¡®ç‡ä»¥åŠ TF-Slim æºç å’Œ checkpoint æ–‡ä»¶ï¼Œæ•°æ®æ¥æºï¼š[TensorFlow-Slim image classification library](https://github.com/tensorflow/models/tree/master/slim)

Model | TF-Slim File | Checkpoint | Top-1 Accuracy| Top-5 Accuracy |
:----:|:------------:|:----------:|:-------:|:--------:|
[Inception V1](http://arxiv.org/abs/1409.4842v1)|[Code](https://github.com/tensorflow/models/blob/master/slim/nets/inception_v1.py)|[inception_v1_2016_08_28.tar.gz](http://download.tensorflow.org/models/inception_v1_2016_08_28.tar.gz)|69.8|89.6|
[Inception V2](http://arxiv.org/abs/1502.03167)|[Code](https://github.com/tensorflow/models/blob/master/slim/nets/inception_v2.py)|[inception_v2_2016_08_28.tar.gz](http://download.tensorflow.org/models/inception_v2_2016_08_28.tar.gz)|73.9|91.8|
[Inception V3](http://arxiv.org/abs/1512.00567)|[Code](https://github.com/tensorflow/models/blob/master/slim/nets/inception_v3.py)|[inception_v3_2016_08_28.tar.gz](http://download.tensorflow.org/models/inception_v3_2016_08_28.tar.gz)|78.0|93.9|
[Inception V4](http://arxiv.org/abs/1602.07261)|[Code](https://github.com/tensorflow/models/blob/master/slim/nets/inception_v4.py)|[inception_v4_2016_09_09.tar.gz](http://download.tensorflow.org/models/inception_v4_2016_09_09.tar.gz)|80.2|95.2|
[Inception-ResNet-v2](http://arxiv.org/abs/1602.07261)|[Code](https://github.com/tensorflow/models/blob/master/slim/nets/inception_resnet_v2.py)|[inception_resnet_v2.tar.gz](http://download.tensorflow.org/models/inception_resnet_v2_2016_08_30.tar.gz)|80.4|95.3|
[ResNet V1 50](https://arxiv.org/abs/1512.03385)|[Code](https://github.com/tensorflow/models/blob/master/slim/nets/resnet_v1.py)|[resnet_v1_50.tar.gz](http://download.tensorflow.org/models/resnet_v1_50_2016_08_28.tar.gz)|75.2|92.2|
[ResNet V1 101](https://arxiv.org/abs/1512.03385)|[Code](https://github.com/tensorflow/models/blob/master/slim/nets/resnet_v1.py)|[resnet_v1_101.tar.gz](http://download.tensorflow.org/models/resnet_v1_101_2016_08_28.tar.gz)|76.4|92.9|
[ResNet V1 152](https://arxiv.org/abs/1512.03385)|[Code](https://github.com/tensorflow/models/blob/master/slim/nets/resnet_v1.py)|[resnet_v1_152.tar.gz](http://download.tensorflow.org/models/resnet_v1_152_2016_08_28.tar.gz)|76.8|93.2|
[ResNet V2 50](https://arxiv.org/abs/1603.05027)^|[Code](https://github.com/tensorflow/models/blob/master/slim/nets/resnet_v2.py)|[resnet_v2_50.tar.gz](http://download.tensorflow.org/models/resnet_v2_50_2017_04_14.tar.gz)|75.6|92.8|
[ResNet V2 101](https://arxiv.org/abs/1603.05027)^|[Code](https://github.com/tensorflow/models/blob/master/slim/nets/resnet_v2.py)|[resnet_v2_101.tar.gz](http://download.tensorflow.org/models/resnet_v2_101_2017_04_14.tar.gz)|77.0|93.7|
[ResNet V2 152](https://arxiv.org/abs/1603.05027)^|[Code](https://github.com/tensorflow/models/blob/master/slim/nets/resnet_v2.py)|[resnet_v2_152.tar.gz](http://download.tensorflow.org/models/resnet_v2_152_2017_04_14.tar.gz)|77.8|94.1|
[VGG 16](http://arxiv.org/abs/1409.1556.pdf)|[Code](https://github.com/tensorflow/models/blob/master/slim/nets/vgg.py)|[vgg_16.tar.gz](http://download.tensorflow.org/models/vgg_16_2016_08_28.tar.gz)|71.5|89.8|
[VGG 19](http://arxiv.org/abs/1409.1556.pdf)|[Code](https://github.com/tensorflow/models/blob/master/slim/nets/vgg.py)|[vgg_19.tar.gz](http://download.tensorflow.org/models/vgg_19_2016_08_28.tar.gz)|71.1|89.8|

æ¨èä¸€ä¸ªè¿˜ç®—ä¸é”™çš„æœºå™¨å­¦ä¹ çš„æ•°æ®ç½‘ç«™ï¼š[kaggle](https://www.kaggle.com)

### è¿ç§»å­¦ä¹ 

ä»å¤´å¼€å§‹è®­ç»ƒä¸€ä¸ªå¤æ‚çš„ç½‘ç»œæ˜¯å¾ˆè´¹æ—¶è´¹åŠ›çš„ï¼Œéœ€è¦è·å–ç¬¦åˆç›®æ ‡çš„æµ·é‡çœŸå®æ•°æ®ï¼Œå¹¶ä½¿ç”¨æ€§èƒ½æå¼ºçš„é›†ç¾¤æ¥è®­ç»ƒæ•°æ®ï¼Œå¹¶æœ‰è¶³å¤Ÿçš„è€å¿ƒç­‰å¾…è®­ç»ƒç»“æœã€‚ç¨æœ‰ä¸æ…ï¼Œè¿˜éœ€è¦ä¸æ–­è°ƒå‚ï¼Œé‡æ–°å†æ¥ã€‚è¿™æ˜¯ä¸ªæ¯ç‡¥ä¹å‘³çš„ä½“åŠ›æ´»ï¼Œå¹¶ä¸”æ˜¯åœ¨æœ‰ç¡¬ä»¶ç»æµå®åŠ›çš„åŸºç¡€ä¸Šæ‰åŠå¾—åˆ°çš„ã€‚æ€»ä¼šçœ‹åˆ°ä¸€äº›è®ºæ–‡é‡Œæè¿°è‡ªå·±çš„æ¨¡å‹ç”¨ Tesla KXX è·‘äº†å¤šä¹…æ‰è®­ç»ƒå‡ºäº†ç»“æœï¼Œå…¶å®åœ¨æœºå™¨å­¦ä¹ é¢†åŸŸï¼ŒèŠ±è´¹åŠå¹´ç”šè‡³æ›´ä¹…çš„æ—¶é—´æ¥è°ƒå‚ä¼˜åŒ–æ¨¡å‹æ˜¯å¾ˆæ­£å¸¸çš„ã€‚

æ‰€ä»¥åŸºäºå·²ç»è®­ç»ƒå¥½çš„æ¨¡å‹å‚æ•°æ¥è¿›è¡Œ fine-tuning ååº”ç”¨åˆ°æ–°çš„æ¨¡å‹ä¸Šæ˜¯ä¸€ä¸ªçœæ—¶çœåŠ›çš„æ–¹æ¡ˆï¼Œä¹Ÿè¢«ç§°ä¹‹ä¸ºè¿ç§»å­¦ä¹ ã€‚å¤§éƒ¨åˆ†æ•°æ®æ˜¯å­˜åœ¨ç›¸å…³æ€§çš„ï¼Œåœ¨å›¾ç‰‡åˆ†ç±»é—®é¢˜ä¸­ï¼Œå³ä¾¿ç°æœ‰æ¨¡å‹ä¸åŒ…å«æˆ‘ä»¬æƒ³è¦çš„åˆ†ç±»ï¼Œä¹Ÿå¯ä»¥åˆ©ç”¨å·²ç»è®­ç»ƒå¥½çš„æƒé‡æ¥è¿›è¡Œ fine-tuningï¼Œä½¿å…¶å¯¹æ–°çš„ç±»åˆ«è¿›è¡Œåˆ†ç±»ã€‚

ä¸€èˆ¬çš„åšæ³•æ˜¯å°†å·²ç»è®­ç»ƒå¥½çš„æ¨¡å‹æƒé‡åŠ è½½ï¼Œé™¤å» top éƒ¨åˆ†ï¼ˆå…¨è¿æ¥å±‚å’Œ softmax åˆ†ç±»å™¨ç­‰ï¼‰ï¼Œå†»ç»“å‰é¢å±‚çº§çš„æƒé‡ï¼Œåªä¿ç•™æƒ³è¦ fine-tuning çš„å±‚çº§ï¼ˆä¸€èˆ¬æ˜¯åé¢çš„å·ç§¯å±‚ï¼‰ï¼Œæœ€åæ ¹æ®åˆ†ç±»ä¸ªæ•°è‡ªå·±æ·»åŠ å…¨è¿æ¥å±‚ã€‚è®­ç»ƒæ—¶åªæœ‰åé¢çš„å±‚çº§æƒé‡æ‰ä¼šè¢«ä¿®æ”¹ï¼Œå‰é¢å·²ç»è®­ç»ƒå¥½çš„æƒé‡ä¸ä¼šæ”¹å˜ã€‚è¿™æ ·ä¼šå¾ˆå¿«å°†æ­£ç¡®ç‡æé«˜åˆ° 90% ä»¥ä¸Šã€‚

è¯¦ç»†å†…å®¹å¯ä»¥å‚è€ƒè¿™ç¯‡æ–‡ç« ï¼š(https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html)

## æ¡†æ¶é€‰æ‹©

æœ‰ä¸€äº›çŸ¥åçš„æ¡†æ¶å¯ä¾›é€‰æ‹©ï¼šTensorFlow, Torch, Caffee, Theano, Keras...

ä¸åŒæ¡†æ¶æ‰€ä½¿ç”¨çš„æ•°æ®æ ¼å¼ä¸ä¸€æ ·ï¼Œä¸»è¦åŒºåˆ«åœ¨äº Channel  é€šé“çš„ä½ç½®æ˜¯åœ¨æœ€å‰è¿˜æ˜¯æœ€åã€‚æ¡†æ¶ä¹‹é—´çš„å­¦ä¹ æˆæœ¬éƒ½ä¸ä¸€æ ·ï¼Œå•æ‹¿ TensorFlow æ¥è¯´ï¼Œå…¶æœ€åŸºç¡€çš„è¯­æ³•éœ€è¦ä¸€ç‚¹ç‚¹æ„å»ºä¸€å¼ å›¾ï¼Œè€Œå…¶ `tf.contrib.learn` å’Œ `tf.contrib.layers` API æ˜¯æ›´é«˜ä¸€å±‚çš„å°è£…ï¼Œè¿˜æœ‰ TF-Slim è¿™ç§æ›´è½»é‡çº§çš„é«˜çº§å°è£…ï¼Œå‡ è¡Œä»£ç å°±èƒ½å¹²å¥½å¤šäº‹ï¼Œçœ‹èµ·æ¥æ›´å±Œã€‚ä½†å…¶å®ç›®å‰ç”±äº TensorFlow çš„å¿«é€Ÿè¿­ä»£ï¼Œå¯¼è‡´ä¸èƒ½å‘ä¸‹å…¼å®¹ï¼Œè€ä»£ç è¿è¡Œä¸èµ·æ¥ã€‚å•æ‹¿ TF-Slim æ¥è¯´ï¼Œå®˜ç½‘ API æ–‡æ¡£ç¼ºå¤±ï¼ŒGithub çš„æ•™ç¨‹ä»£ç è€æ—§æ— æ³•è¿è¡Œï¼Œè¿˜åœ¨ä½¿ç”¨ä» model åº“ merge åˆ° tensorflow ä¹‹å‰çš„è¯­æ³•ã€‚æˆ‘å½“æ—¶æœ¬æƒ³ç”¨ TF-Slim å¿«é€ŸéªŒè¯ä¸€äº›æ¨¡å‹ï¼Œç»“æœæ²¡æƒ³åˆ°åè€Œæµªè´¹äº†å¤§é‡æ—¶é—´ï¼Œå¾—ä¸å¿å¤±ã€‚

Keras åŸºäº TensorFlow æˆ– Theanoï¼Œé›†æˆäº†å¤§é‡åŠŸèƒ½ï¼Œæ˜¯ä¸€ç§æ–¹ä¾¿å¿«é€ŸéªŒè¯ idea çš„é«˜å±‚ APIã€‚ å†…ç½®å¤§é‡å¸¸ç”¨ç½‘ç»œï¼Œå¾ˆå®¹æ˜“ä¸Šæ‰‹ï¼Œè¯­æ³•ç®€æ´ï¼ŒåŠŸèƒ½å¼ºå¤§åˆä¸å¤±å¯å®šåˆ¶æ€§ã€‚å¼ºåŠ›æ¨èï¼Œå®˜æ–¹æ–‡æ¡£ï¼š[Keras Documentation](https://keras.io)ï¼Œä¸­æ–‡æ–‡æ¡£ï¼š[Keras ä¸­æ–‡æ–‡æ¡£](http://keras-cn.readthedocs.io/en/latest/)

æ— è®ºæ˜¯å“ªç§æ¡†æ¶ï¼Œå‡ ä¹éƒ½æ˜¯åŸºäºåˆ†å¸ƒå¼è®¾è®¡çš„æ€æƒ³ï¼Œå…ˆæè¿°å‡ºè®¡ç®—å›¾ï¼Œç„¶åå†å‘å›¾ä¸­å¡«å……æ•°æ®æµï¼Œä½¿å…¶è¿è½¬èµ·æ¥ï¼Œæœ€åå¾—åˆ°ç»“æœã€‚è™½ç„¶æ˜¯ä½¿ç”¨ Python è¯­è¨€æ¥æè¿°è®¡ç®—å›¾ï¼Œä½†æ˜¯çœŸæ­£ç¹é‡çš„å·¥ä½œéƒ½ä¼šæäº¤ç»™åº•å±‚çš„åç«¯å»å¤„ç†ã€‚ä½†è¿™æ ·ä¹Ÿç»™ debug å¸¦æ¥äº†å›°éš¾ï¼Œå› ä¸ºæè¿°è®¡ç®—å›¾çš„æ—¶å€™å¹¶ä¸èƒ½å¾—åˆ°æ•°æ®ç»“æœï¼Œåªèƒ½æ£€æŸ¥å‡ºæ•°æ®æ ¼å¼æ˜¯å¦åŒ¹é…ã€‚

> ç¬¼ç»Ÿçš„è¯´ï¼Œç¬¦å·ä¸»ä¹‰çš„è®¡ç®—é¦–å…ˆå®šä¹‰å„ç§å˜é‡ï¼Œç„¶åå»ºç«‹ä¸€ä¸ªâ€œè®¡ç®—å›¾â€ï¼Œè®¡ç®—å›¾è§„å®šäº†å„ä¸ªå˜é‡ä¹‹é—´çš„è®¡ç®—å…³ç³»ã€‚å»ºç«‹å¥½çš„è®¡ç®—å›¾éœ€è¦ç¼–è¯‘ä»¥ç¡®å®šå…¶å†…éƒ¨ç»†èŠ‚ï¼Œç„¶è€Œï¼Œæ­¤æ—¶çš„è®¡ç®—å›¾è¿˜æ˜¯ä¸€ä¸ªâ€œç©ºå£³å­â€ï¼Œé‡Œé¢æ²¡æœ‰ä»»ä½•å®é™…çš„æ•°æ®ï¼Œåªæœ‰å½“ä½ æŠŠéœ€è¦è¿ç®—çš„è¾“å…¥æ”¾è¿›å»åï¼Œæ‰èƒ½åœ¨æ•´ä¸ªæ¨¡å‹ä¸­å½¢æˆæ•°æ®æµï¼Œä»è€Œå½¢æˆè¾“å‡ºå€¼ã€‚
	å°±åƒç”¨ç®¡é“æ­å»ºä¾›æ°´ç³»ç»Ÿï¼Œå½“ä½ åœ¨æ‹¼æ°´ç®¡çš„æ—¶å€™ï¼Œé‡Œé¢æ˜¯æ²¡æœ‰æ°´çš„ã€‚åªæœ‰æ‰€æœ‰çš„ç®¡å­éƒ½æ¥å®Œäº†ï¼Œæ‰èƒ½é€æ°´ã€‚
	-- å¼•è‡ª http://keras-cn.readthedocs.io/en/latest/for_beginners/concepts/
	
## æ•°æ®é‡‡é›†

å› ä¸ºç½‘ä¸Šæä¾›çš„ä¸€äº›ç”¨äºè®­ç»ƒçš„æµ·é‡å›¾ç‰‡æ•°æ®éƒ½æ˜¯æ ¼å¼æ•´é½åƒç´ è¾ƒä½çš„å›¾ç‰‡ï¼Œæ¯”å¦‚28x28è¿™ç§ï¼Œä¸”ç‰¹å¾æ˜æ˜¾ï¼Œéƒ½ä¸ºæŸç§ç‰©ä½“ï¼Œè¿™ç§ä¸“ç”¨äºæ¯”èµ›æŒ‘æˆ˜çš„å›¾ç‰‡åˆ†ç±»æ•°é‡ä¸€èˆ¬éƒ½æ˜¯10ï¼Œ100ï¼Œ1000ç­‰ï¼Œæ›´ä¸“æ³¨äºç®—æ³•çš„å‡†ç¡®ç‡ï¼Œå¿½è§†äº†çœŸå®çš„åœºæ™¯ã€‚

ä¸ºäº†æ¨¡æ‹ŸçœŸå®åœºæ™¯ï¼Œæˆ‘ä½¿ç”¨ Web ç¨‹åºè°ƒç”¨ iMac å‰ç½®æ‘„åƒå¤´é‡‡é›† 320x240 å°ºå¯¸çš„ç…§ç‰‡ã€‚ä¸ºäº†æ›´é«˜æ•ˆé‡‡é›†å›¾ç‰‡æ•°æ®ï¼Œæˆ‘é‡‡ç”¨è¿æ‹çš„æ–¹å¼æ‹æ‘„å¹¶ä¿å­˜å›¾ç‰‡åˆ°æœ¬åœ°ï¼š

![å¸…æ˜¯æˆ‘çš„æ— å¥ˆ](http://yulingtianxia.com/resources/MachineLearning/training_data.png)

éœ€è¦å»é™¤å°‘é‡è¿‡äºæ¨¡ç³Šå’Œæ‰‹æŒ‡ä¸å°å¿ƒè·‘å‡ºå±å¹•å¤–çš„å›¾ç‰‡ï¼Œå°½å¯èƒ½æé«˜æ•°æ®çš„è´¨é‡ã€‚

å› ä¸ºä¸åŒå¹³å°å’Œæµè§ˆå™¨å¯¹ Html5 è§„èŒƒæ”¯æŒç¨‹åº¦ä¸åŒï¼Œå»ºè®®åœ¨ Mac ä¸Šä½¿ç”¨ Firefoxï¼ŒWindows ä¸Šåº”è¯¥ Chrome ä¹Ÿå¥½ä½¿ï¼Œä½†æ²¡è¯•è¿‡ã€‚

å›¾åƒé‡‡é›†çš„ä»£ç æ”¾åœ¨ [captureImages](https://github.com/yulingtianxia/HandGestureCNN/tree/master/captureImages) ç›®å½•é‡Œã€‚

## Inception V3 pre-trained network

åœ¨ Keras Blog ä¸­ï¼Œ[Building powerful image classification models using very little data](https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html) å¾ˆå¥½åœ°ä»‹ç»äº†å¦‚ä½•é’ˆå¯¹å°æ•°æ®é›†åˆ©ç”¨ç°æœ‰çš„ VGG16 ç½‘ç»œ fine-tuningï¼Œå¹¶åœ¨ [Dogs vs. Cats](https://www.kaggle.com/c/dogs-vs-cats/data) æ•°æ®é›†ä¸Šå–å¾—äº† 94% çš„å‡†ç¡®ç‡ã€‚

VGG ç³»åˆ—ç½‘ç»œè™½ç„¶ç»“æ„ç®€å•æ˜“ç†è§£ï¼Œä½†æ— è®ºæ˜¯åŠ è½½æƒé‡çš„è€—æ—¶è¿˜æ˜¯é¢„æµ‹è€—æ—¶éƒ½è¦æ¯” Inception ç³»åˆ—ç½‘ç»œè¦é•¿ï¼Œè¿™æ˜¯å› ä¸ºå…¶æƒé‡æ•°æ®æ›´å¤šã€‚è™½ç„¶ Inception ç³»åˆ—æ›´å¤æ‚ï¼Œä½†é‰´äºå…¶ä¼˜ç§€çš„æ€§èƒ½å’Œæ›´èƒœä¸€ç­¹çš„å‡†ç¡®ç‡ï¼Œæˆ‘å†³å®šåœ¨ç§»åŠ¨è®¾å¤‡ä¸Šä½¿ç”¨ Inception è€Œé VGGã€‚

å…¶å®è‹¹æœçˆ¸çˆ¸å·²ç»å¸®æˆ‘ä»¬ç”¨ Swift å’Œ Metal Performance Shaders å®ç°äº†ä¸ªä½¿ç”¨ Inception V3 ç½‘ç»œé¢„æµ‹å›¾åƒç±»åˆ«çš„ Demo:[MetalImageRecognition: Performing Image Recognition with Inception_v3 Network using Metal Performance Shaders Convolutional Neural Network routines](https://developer.apple.com/library/content/samplecode/MetalImageRecognition/Introduction/Intro.html)

æ‰€ä»¥æˆ‘å†³å®šä½¿ç”¨ [Inception V3 Network](https://arxiv.org/pdf/1512.00567v3.pdf) æ¥ fine-tuningï¼Œè¿™æ ·åœ¨åç»­çš„ MPS ä»£ç ç¼–å†™ä¸Šå°±ä¼šçœå¾ˆå¤šæ—¶é—´ã€‚TensorFlow å®˜æ–¹ä¹Ÿæœ‰ç›¸åº” [æ•™ç¨‹](https://www.tensorflow.org/tutorials/image_recognition#image-recognition)ã€‚


### bottleneck features

ä¸‹å›¾å±•ç¤ºäº† Inception V3 ç½‘ç»œçš„ç»“æ„ï¼Œå…¶ä¸­çš„ top éƒ¨åˆ†å°±æ˜¯ Final part æ‰€æŒ‡çš„éƒ¨åˆ†ï¼Œæˆ‘ä»¬å¯ä»¥å°†å…¶æ›¿æ¢æˆæˆ‘ä»¬è‡ªå·±çš„å…¨è¿æ¥å±‚ï¼Œåˆ©ç”¨å‰é¢ Input é¢„æµ‹çš„ç»“æœæ¥ä½œä¸ºè¾“å…¥æ•°æ®ï¼Œè®­ç»ƒæˆ‘ä»¬è‡ªå·±çš„åˆ†ç±»å™¨ã€‚

![](http://yulingtianxia.com/resources/MachineLearning/Inception V3.png)

> ä¸Šå›¾ä¸­çš„ Inception mudules ä½¿ç”¨çš„æ˜¯[è®ºæ–‡](https://arxiv.org/pdf/1512.00567v3.pdf)ä¸­æåˆ°çš„å›¾ 6 çš„ç»“æ„ï¼Œå®é™…ä»£ç ä¸­åˆ™ä½¿ç”¨çš„å›¾ 5ã€‚

Keras æœ‰å¾ˆå¤šä½¿ç”¨ ImageNet é¢„è®­ç»ƒçš„æ¨¡å‹ï¼Œæˆ‘ä»¬è¿™é‡Œåªéœ€è¦ Inception V3 å»æ‰ Final part çš„å‰©ä½™éƒ¨åˆ†ï¼Œä¸€è¡Œä»£ç æå®šï¼š

```
model = applications.InceptionV3(include_top=False, weights='imagenet')
```

åœ¨ TensorFlow ä¸­è¯»å–æ–‡ä»¶æ•°æ®éœ€è¦é€šè¿‡ `QueueRunner` å’Œ `Coordinator` æ„é€ é˜Ÿåˆ—æ¥å®ç° data flowï¼Œæ¯”è¾ƒéº»çƒ¦ï¼š

![å›¾ç‰‡æ¥æº TensorFlow](http://yulingtianxia.com/resources/MachineLearning/AnimatedFileQueues.gif)

Keras çœŸæ˜¯å¤ªæ–¹ä¾¿äº†ï¼Œç”¨ç”Ÿæˆå™¨æŠŠå›¾ç‰‡æ•°æ®æ ‡å‡†åŒ–ï¼Œä½¿ç”¨åŠ è½½å¥½çš„ `model` é¢„æµ‹å‡ºç»“æœï¼Œå¹¶ä¿å­˜åˆ° npy æ–‡ä»¶ä¸­ã€‚

```
datagen = ImageDataGenerator(rescale=1. / 255)
generator = datagen.flow_from_directory(
   train_data_dir,
   target_size=(img_width, img_height),
   batch_size=batch_size,
   class_mode=None,
   shuffle=False)
bottleneck_features_train = model.predict_generator(
   generator, nb_train_samples // batch_size)
np.save(open('bottleneck_features_train.npy', 'w'),
       bottleneck_features_train)
```

è¿™é‡Œä¿å­˜çš„ç»“æœå¹¶ä¸æ˜¯ one-hot æ ¼å¼çš„åˆ†ç±»ç»“æœï¼Œåªæ˜¯ä½œä¸º Final part çš„è¾“å…¥ï¼Œæ‰€ä»¥å«åš bottleneck featuresã€‚

ä¸‹ä¸€æ­¥å°±æ˜¯æ„å»ºè‡ªå·±çš„ Final partï¼Œæ¯”å¦‚æˆ‘ä»¬è¿™é‡Œæƒ³è¦åšä¸ªäº”åˆ†ç±»çš„æ¨¡å‹ï¼š

```
model = Sequential()
model.add(Flatten(input_shape=train_data.shape[1:]))
model.add(Dense(256, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(5, activation='softmax'))
```

`Flatten` å’Œ `Dropout` å±‚å¹¶ä¸ä¼šæ”¹å˜æ•°æ®ï¼Œæ˜¯æ²¡æœ‰æƒé‡çš„å±‚ã€‚æ‰€ä»¥è¿™é‡Œæœ‰ä¸¤ä¸ªå…¨è¿æ¥å±‚ï¼Œæœ€åä¸€å±‚æœ‰äº”ä¸ªèŠ‚ç‚¹ï¼Œè¾“å‡ºä¸€ä¸ªé•¿åº¦ä¸º 5 çš„ one-hot æ ¼å¼å‘é‡ã€‚

è¿™é‡Œä¹‹æ‰€ä»¥ä½¿ç”¨ bottleneck features ä½œä¸ºè¾“å…¥æ•°æ®æ¥è¿›è¡Œè®­ç»ƒï¼Œæ˜¯ä¸ºäº†èŠ‚çœè¿ç®—èµ„æºã€‚å¦‚æœé‡‡ç”¨å†»ç»“å‰é¢éƒ¨åˆ†ç½‘ç»œçš„æ–¹å¼ï¼Œè™½ç„¶è¢«å†»ç»“çš„ç½‘ç»œæƒé‡ä¸ä¼šå˜ï¼Œä½†æ¯è·‘ä¸€æ¬¡çš„è¿ç®—é‡éƒ½å¾ˆå¤§ï¼Œè€Œä¸”ç»“æœæ˜¯ç›¸åŒçš„ã€‚æ‰€ä»¥é‡‡å–é¢„æµ‹ä¸€æ¬¡ bottleneck featuresï¼Œç¦»çº¿ä¿å­˜çš„æ–¹å¼ã€‚åœ¨æœºå™¨å­¦ä¹ ä¸­å‡å°‘ loss æå‡å‡†ç¡®ç‡å¸¸ç”¨çš„æ–¹æ³•å°±æ˜¯æ¢¯åº¦ä¸‹é™æ³•ï¼Œå®é™…åº”ç”¨ä¸­ä½¿ç”¨ mini-batch æ¢¯åº¦ä¸‹é™æ³•æ¥å¹³è¡¡è®¡ç®—æ€§èƒ½å’Œ loss æ”¶æ•›æ•ˆæœã€‚è¿™é‡Œçš„ batch_size å°±æ˜¯æ¯æ¬¡ä¸‹é™æ‰€ä½¿ç”¨æ•°æ®æ‰¹æ¬¡çš„æ•°é‡ã€‚

```
model.compile(optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),
             loss='categorical_crossentropy', metrics=['accuracy'])

model.fit(train_data, train_labels,
         epochs=epochs,
         batch_size=batch_size,
         validation_data=(validation_data, validation_labels))
model.save_weights(top_model_weights_path)
```

è¿™é‡Œè®­ç»ƒçš„æ˜¯æˆ‘ä»¬è‡ªå·±æ·»åŠ çš„ä¸¤ä¸ªå…¨è¿æ¥å±‚ï¼Œä»¥ä¾¿äºæ‹Ÿåˆæˆ‘ä»¬è‡ªå·±çš„æ•°æ®ã€‚

è¿™éƒ¨åˆ†çš„æºç æ”¾åœ¨ [bottleneck_features_train_inceptionv3.py](https://github.com/yulingtianxia/HandGestureCNN/blob/master/Train/bottleneck_features_train_inceptionv3.py)

### Fine-tuning 

ä¸ºäº†è¾¾åˆ°æ›´å¥½çš„æ•ˆæœï¼Œå¯ä»¥è§£å†»åé¢å‡ å±‚ã€‚çœ‹äº†ä¸‹ Inception V3 çš„ç½‘ç»œç»“æ„ï¼Œæœ€åä¸€ä¸ª tower æ‹¥æœ‰ 9 ä¸ªå·ç§¯å±‚ï¼Œæ¯”è¾ƒå¤æ‚ã€‚è™½ç„¶ç†è®ºä¸Š fine-tuneing æ•´ä¸ª tower æ˜¯å¯è¡Œçš„ï¼Œä½†æ˜¯è®¡ç®—å¼€é”€å¾ˆå¤§ï¼Œç”¨æˆ‘çš„ iMac 4 GHz Intel Core i7 å…«æ ¸è·‘ä¸€ä¸ªæœˆéƒ½ä¸è¡Œã€‚

ç°åœ¨éœ€è¦åŠ è½½é¢„è®­ç»ƒç½‘ç»œçš„æƒé‡åˆ° `base_model` ä¸­ï¼Œå¹¶å°†å…¶ä¸ `top_model` æ‹¼åœ¨ä¸€èµ·ã€‚Keras ä¸­æœ‰ä¸¤ç§æè¿°æ¨¡å‹ï¼Œä¸€ç§æ˜¯ `Sequential`ï¼Œå¦ä¸€ç§æ˜¯å¸¦æœ‰å‡½æ•°å¼ API çš„ `Model`ã€‚å‰è€…å±‚ä¸å±‚ä¹‹å‰è¿æ¥çš„å…¥åº¦å’Œå‡ºåº¦éƒ½ä¸º 1ï¼Œåè€…å°±å¾ˆçµæ´»å¾ˆéšæ„äº†ã€‚è¿™é‡Œæ„å»º `top_model` ä½¿ç”¨çš„ `Sequential`ï¼Œç„¶åä½¿ç”¨ `Model` ç»Ÿä¸€è¾“å…¥å’Œè¾“å‡ºï¼Œèµ·åˆ°è¿æ¥çš„ä½œç”¨ã€‚æœ€åé€šè¿‡è®¾ç½® `trainable` å±æ€§æ¥å†»ç»“éƒ¨åˆ†ç½‘ç»œã€‚ä¸ºäº†è®©å‡†ç¡®ç‡æ›´é«˜ï¼Œä¼šå°†ä¸Šä¸€æ­¥ bottleneck features è®­ç»ƒå¥½çš„æƒé‡ä½œä¸º `top_model` çš„åˆå§‹æƒé‡ã€‚

```
# build the InceptionV3 network
input_tensor = Input(shape=(img_height, img_width, 3))
base_model = applications.InceptionV3(weights='imagenet', include_top=False, input_tensor=input_tensor)
print('Model loaded.')

# build a classifier model to put on top of the convolutional model
top_model = Sequential()
top_model.add(Flatten(input_shape=base_model.output_shape[1:]))
top_model.add(Dense(256, activation='relu'))
top_model.add(Dropout(0.5))
top_model.add(Dense(5, activation='softmax'))

# note that it is necessary to start with a fully-trained
# classifier, including the top classifier,
# in order to successfully do fine-tuning
top_model.load_weights(top_model_weights_path)

# add the model on top of the convolutional base
model = Model(inputs=base_model.input, outputs=top_model(base_model.output))

# set the first xx layers (up to the last conv block)
# to non-trainable (weights will not be updated)

for layer in model.layers[:len(base_model.layers)-5]:
    layer.trainable = False
```

æœ‰å…³ Keras ä¸¤ç§æ¨¡å‹çš„æ¦‚å¿µå¯ä»¥æŸ¥çœ‹ [About Keras models](https://keras.io/models/about-keras-models/)ã€‚

å¯ä»¥é€šè¿‡è®¾ç½®æ•°æ®ç”Ÿæˆå™¨çš„ä¸€äº›å‚æ•°æ¥æå‡æ•°æ®çš„éšæœºæ€§ï¼Œé™ä½è¿‡æ‹Ÿåˆã€‚`ImageDataGenerator` é’ˆå¯¹å›¾ç‰‡æœ‰å¾ˆå¤šé¢„è®¾çš„å¤„ç†æ–¹å¼ï¼Œä¾‹å¦‚å¹³ç§»ï¼Œæ—‹è½¬ï¼Œç¼©æ”¾ï¼Œåè½¬ç­‰ã€‚TensorFlow ä¸­ä¹Ÿæœ‰ç±»ä¼¼çš„å›¾ç‰‡é¢„å¤„ç†åŠŸèƒ½ï¼Œä½† API ä½¿ç”¨ä¸Šæ²¡ Keras ä¾¿åˆ©ã€‚æœ‰å…³å›¾ç‰‡é¢„å¤„ç†çš„å†…å®¹å¯ä»¥å‚è€ƒæ–‡æ¡£ [Image Preprocessing](https://keras.io/preprocessing/image/)ï¼Œè¿™é‡Œä»…é’ˆå¯¹æŸäº›æ–¹å¼è¿›è¡Œéšæ„é¢„å¤„ç†ï¼Œæå‡æ•°æ®ï¼š

```
train_datagen = ImageDataGenerator(
	rescale=1./255,
  	rotation_range=40,
  	width_shift_range=0.2,
  	height_shift_range=0.2,
  	shear_range=0.2,
  	zoom_range=0.2,
  	horizontal_flip=True,
  	fill_mode='nearest')
```

Keras å¯ä»¥æ ¹æ®æ•°æ®çš„æ–‡ä»¶å¤¹è‡ªåŠ¨åˆ†ç±»æ‰“æ ‡ç­¾ï¼Œæ‰€ä»¥æˆ‘å°†å›¾ç‰‡æŒ‰æ–‡ä»¶å¤¹å½’ç±»å°±å¯ä»¥äº†ï¼Œå¾ˆæ–¹ä¾¿ã€‚

æˆ‘ä¸€å…±ä½¿ç”¨äº† 1808 å¼ å›¾ç‰‡ä½œä¸ºè®­ç»ƒé›†ï¼Œ192 å¼ å›¾ç‰‡ä½œä¸ºäº¤å‰éªŒè¯é›†ã€‚ç»è¿‡äº† 50 ä¸ª epoch åï¼Œè®­ç»ƒé›†å‡†ç¡®ç‡ 96.26%ï¼Œäº¤å‰éªŒè¯é›†å‡†ç¡®ç‡ 73.86%ã€‚

è¿™éƒ¨åˆ†æºç æ”¾åœ¨ [finetune_inceptionv3.py](https://github.com/yulingtianxia/HandGestureCNN/blob/master/Train/finetune_inceptionv3.py)

## Convert HDF5 to binary .dat files

> HDFï¼ˆè‹±è¯­ï¼šHierarchical Data Formatï¼‰æŒ‡ä¸€ç§ä¸ºå­˜å‚¨å’Œå¤„ç†å¤§å®¹é‡ç§‘å­¦æ•°æ®è®¾è®¡çš„æ–‡ä»¶æ ¼å¼åŠç›¸åº”åº“æ–‡ä»¶ã€‚HDFæœ€æ—©ç”±NCSAå¼€å‘ï¼Œç›®å‰åœ¨éç›ˆåˆ©ç»„ç»‡ HDF å°ç»„ç»´æŠ¤ä¸‹ç»§ç»­å‘å±•ã€‚å½“å‰æµè¡Œçš„ç‰ˆæœ¬æ˜¯HDF5ã€‚
	-- ç»´åŸºç™¾ç§‘
	
[HDF Group](https://www.hdfgroup.org) æä¾›äº†å¯è§†åŒ–æŸ¥çœ‹ HDF æ–‡ä»¶çš„å·¥å…·ï¼š[HDFView](https://support.hdfgroup.org/products/java/release/download.html)ï¼Œå› ä¸ºæ˜¯ç”¨ java å†™çš„ï¼Œæ‰€ä»¥æ˜¯è·¨å¹³å°çš„ã€‚Mac ç‰ˆæœ¬æœ‰ä¸ªå·²çŸ¥çš„ bugï¼šåŒå‡»ä¸€ä¸ª `.h5` æ–‡ä»¶å HDFView ç•Œé¢æ˜¯ç©ºçš„ï¼Œéœ€è¦æŠŠ `.h5` æ–‡ä»¶æ‹–åŠ¨åˆ° HDFView å·¦è¾¹æ æ‰èƒ½æ‰“å¼€ã€‚

![](http://yulingtianxia.com/resources/MachineLearning/HDFView.jpg)

Keras å¯ä»¥å°†è®­ç»ƒå¤„çš„æƒé‡ç»“æœé«˜å­˜æˆ HDF5 æ ¼å¼ï¼Œä½†è‹¹æœæä¾›çš„ Demo ä½¿ç”¨çš„æƒé‡æ–‡ä»¶æ˜¯ memory-mapped äºŒè¿›åˆ¶æ–‡ä»¶ï¼Œæ¯å±‚ç½‘ç»œéƒ½å¯¹åº”ä¸€ä¸ª `.dat` æ–‡ä»¶ã€‚

[SOFTWARE USING HDF5](https://support.hdfgroup.org/products/hdf5_tools/index.html) åˆ—ä¸¾äº†å¾ˆå¤šç”¨äºæ“ä½œ HDF æ–‡ä»¶å’Œæ ¼å¼è½¬æ¢çš„å·¥å…·ã€‚å¯ä»¥ç”¨ä¸€äº›å·¥å…·å°†å­˜æœ‰æƒé‡çš„ HDF æ–‡ä»¶å…ˆè½¬åŒ–æˆè‹¥å¹² `.dat` æ–‡ä»¶ï¼Œç„¶åå†æ‰“åŒ…åˆ° iOS App ä¸­ã€‚è¿˜æœ‰ä¸€ç§åšæ³•æ˜¯å°† HDF æ–‡ä»¶æ‰“åŒ…åˆ° iOS App ä¸­ï¼Œç„¶ååœ¨å®¢æˆ·ç«¯å®Œæˆæ ¼å¼å¯¼å‡ºã€‚[HDF5Kit](https://github.com/aleph7/HDF5Kit) æ˜¯å¯¹ [HDF æºç ](https://support.hdfgroup.org/ftp/HDF5/releases/hdf5-1.10/)çš„ Swift å°è£…ï¼Œä¸è¿‡è¿˜æœ‰äº› crashã€‚æˆ‘é‡‡ç”¨äº†ç¬¬äºŒç§åšæ³•ï¼Œå› ä¸ºæˆ‘æ‡’ï¼Œæ›¿æ¢æƒé‡æ–‡ä»¶çš„æ—¶å€™åªéœ€è¦ä¸€ä¸ª HDF æ–‡ä»¶ï¼Œä¸ç”¨æ›¿æ¢ä¸€å † `.dat` æ–‡ä»¶ğŸ™„ã€‚å®é™…åº”ç”¨ä¸­åƒä¸‡åˆ«è¿™ä¹ˆå¹²ã€‚

å¯ä»¥æ ¹æ®ä¸Šå›¾ä¸­ HDFView å±•ç¤ºçš„æ ‘çŠ¶å±‚çº§é€’å½’éå† Groupï¼Œå¹¶æ‹¼æ¥å¥½æ­£ç¡®çš„åç§°ã€‚æ¯”å¦‚ "bias:0" å’Œ "kernel:0"ã€‚å°† HDF5 è½¬æ¢æˆäºŒè¿›åˆ¶æ–‡ä»¶çš„ä»£ç å¦‚ä¸‹ï¼š

```
// Read parameters from HDF5 file and store to dat file in Tmp directory
func extractHDF5(h5Name: String) {
    // MARK: Parse HDF5 file
    guard let path = Bundle.main.path(forResource: h5Name, ofType: "h5") else {
        fatalError("Failed to get a path")
    }
    guard let file = File.open(path, mode: .readOnly) else {
        fatalError("Failed to open file at \(path)")
    }
    
    guard let layerNamesStringAttribute = file.openStringAttribute("layer_names") else {
        fatalError("Failed to open attribute 'layer_names'")
    }
    guard let layerNames = try? layerNamesStringAttribute.read() else {
        fatalError("Failed to get layer names")
    }
    
    // count used for file name later
    var countOfConvLayer = 0
    var countOfFcLayer   = 0
    var partOfFileName = ""
    
    for layerName in layerNames {
        guard let layerGroup = file.openGroup(layerName) else {
            fatalError("Failed to open group of \(layerName)")
        }
        for objectName in layerGroup.objectNames() {
            
            // only the layer that has parameters remain
            guard let wtDataset = layerGroup.openFloatDataset(objectName + "/kernel:0") else {
                fatalError("Failed to open data set of \(objectName)/kernel:0")
            }
            guard let bsDataset = layerGroup.openFloatDataset(objectName + "/bias:0") else {
                fatalError("Failed to open data set of \(objectName)/bias:0")
            }
            
            var dimension = wtDataset.space.dims
            guard var wtArray = try? wtDataset.read() else {
                fatalError("Failed to read data set of \(objectName)/kernel:0")
            }
            guard var bsArray = try? bsDataset.read() else {
                fatalError("Failed to read data set of \(objectName)/bias:0")
            }
            
            let wtLength = wtArray.count
            let bsLength = bsArray.count
            
            if dimension.count == 4 {
                // weights for convolution layer
                wtArray = SwapAxes.for4dFlatArray(originalArray: wtArray, axis1: 2, axis2: 3, dimensionOfArray: &dimension)
                wtArray = SwapAxes.for4dFlatArray(originalArray: wtArray, axis1: 1, axis2: 2, dimensionOfArray: &dimension)
                wtArray = SwapAxes.for4dFlatArray(originalArray: wtArray, axis1: 0, axis2: 1, dimensionOfArray: &dimension)
                
                countOfConvLayer += 1
                partOfFileName = "conv" + String(countOfConvLayer)
                
            } else if dimension.count == 2 {
                // weights for fully connected layer
                wtArray = SwapAxes.for2dFlatArray(originalArray: wtArray, axis1: 0, axis2: 1, dimensionOfArray: &dimension)
                
                countOfFcLayer += 1
                partOfFileName = "fc" + String(countOfFcLayer)
                
            } else {
                fatalError("Dataset's dimension is neither 4 (convolution layer) nor 2 (fully connected layer)")
            }
            
            let wtData = NSData(bytes: &wtArray, length: wtLength * MemoryLayout<Float>.size)
            let bsData = NSData(bytes: &bsArray, length: bsLength * MemoryLayout<Float>.size)
            
            // å†™å…¥æ•°æ®åˆ°æ–‡ä»¶...
        }
    }
}
```

## Metal Performance Shaders

### MPS ç®€ä»‹

Metal Performance Shaders ç®€ç§° MPSï¼Œå¯ä»¥ä¸ºä½¿ç”¨ Metal æŠ€æœ¯çš„ App æä¾›åº•å±‚é«˜æ€§èƒ½ GPU è¿ç®—æ¥å£ã€‚æœ€åˆè‹¹æœæä¾›çš„ Shader è¯­è¨€æœ¬æ¥æ˜¯å¾ˆåº•å±‚å¾ˆç”Ÿæ¶©çš„ï¼Œåæ¥ä¸º iOS æä¾›äº†åŸç”Ÿæ”¯æŒçš„ APIï¼Œå¯ä»¥ç”¨ Swift æˆ– OC æ¥è°ƒç”¨åº•å±‚æ¥å£äº†ã€‚iOS 9 çš„ MPS æä¾›äº†å›¾ç‰‡ç‰¹æ•ˆå¤„ç†å’Œ Metal çº¹ç†ç›¸å…³çš„ APIï¼ŒiOS 10 çš„ MPS æ–°å¢äº†æœ‰å…³ CNN å’ŒçŸ©é˜µä¹˜æ³•çš„ APIã€‚ä¸è¿‡ç›®å‰è‹¹æœåªå¼€æ”¾äº† CNN çš„é¢„æµ‹åŠŸèƒ½ï¼Œå¦‚æœæƒ³è¦åœ¨ iOS 10 ä¸Šè®­ç»ƒä¸€ä¸ª CNNï¼Œé‚£å°±åªèƒ½å€ŸåŠ©ç¬¬ä¸‰æ–¹å·¥å…·äº†ã€‚

è‹¹æœçš„ BNNS åŒæ ·æä¾›äº†åˆ›å»º CNN çš„ APIï¼Œè€Œä¸”ä¹Ÿåªèƒ½ä½¿ç”¨è®­ç»ƒå¥½çš„æƒé‡è¿›è¡Œé¢„æµ‹ã€‚ä½†ä»…ä»…æ˜¯å¯¹ CPU è¿›è¡Œäº†ä¼˜åŒ–ã€‚å› ä¸º OpenGL çš„é™åˆ¶ï¼Œå…¶æ€§èƒ½ä¸ Metal ç›¸æ¯”å¹¶ä¸å ä¼˜åŠ¿ã€‚OpenCL åœ¨ iOS ä¸Šæ˜¯ç§æœ‰æ¡†æ¶ã€‚æ‰€ä»¥è¯´ç›®å‰çœ‹æ¥ï¼Œä¸è€ƒè™‘ç³»ç»Ÿå…¼å®¹æ€§(iOS 10)å’Œèµ„æºé™åˆ¶(arm64)ï¼ŒMetal æŠ€æœ¯æ˜¯å‘æŒ¥ GPU è¿ç®—ä¼˜åŠ¿çš„æœ€å¥½é€‰æ‹©ã€‚

MPS ç³»ç»ŸåŸç”Ÿæ”¯æŒä¸ç”¨æ‹…å¿ƒå®‰è£…åŒ…å¢é‡é—®é¢˜ï¼Œå¹¶ä¸”ä½¿ç”¨ Metal æŠ€æœ¯ä½¿ç”¨ GPU åŠ é€Ÿè¿ç®—ï¼ŒåŠŸè€—å‘çƒ­å°‘ã€‚MPS ç›®å‰çš„ç¼ºç‚¹æ˜¯ä¸æ”¯æŒç½‘ç»œçš„è®­ç»ƒå’Œå¿…é¡» HardCode ç½‘ç»œç»“æ„ï¼Œä½†é¢å¯¹å¤æ‚åº¦è¾ƒä½çš„ç¥ç»ç½‘ç»œæ—¶è¿˜æ˜¯å¾ˆå®ç”¨çš„ã€‚æ¯•ç«Ÿ TensorFlow åœ¨ iOS ä¸Šåªèƒ½ç”¨ CPU è®¡ç®—ï¼Œä¸”ç¼–è¯‘è´¹æ—¶è´¹åŠ›ï¼Œå®‰è£…åŒ…å¢é‡å·¨å¤§ã€‚

MPS åœ¨æˆ‘çš„ iPhone 6s Plus ä¸Šæ€§èƒ½å¾ˆå¥½ï¼Œå‘çƒ­ä¹Ÿå°‘ï¼Œå¯ä»¥é€šè¿‡ç¥ç»ç½‘ç»œå®æ—¶é¢„æµ‹å‡ºç»“æœã€‚è¿™æ˜¯ [iOS-10-Sampler](https://github.com/shu223/iOS-10-Sampler) é¡¹ç›®çš„æ•ˆæœï¼Œå®ƒæ˜¯åœ¨è‹¹æœå®˜æ–¹ Demo [MetalImageRecognition](https://developer.apple.com/library/content/samplecode/MetalImageRecognition/Introduction/Intro.html) åŸºç¡€ä¸Šç¨å¾®æ”¹è¿›æ‹æ‘„åŠŸèƒ½çš„ç”¨æˆ·ä½“éªŒï¼ŒMPS çš„éƒ¨åˆ†æœªåšä»»ä½•æ”¹åŠ¨ã€‚æˆ‘åŸºäºå®ƒå’Œ [MPSCNNfeeder](https://github.com/kazoo-kmt/MPSCNNfeeder) å®ç°äº† [HandGestureCNN](https://github.com/yulingtianxia/HandGestureCNN/tree/master/HandGestureCNN)ã€‚

![](https://github.com/shu223/iOS-10-Sampler/blob/master/README_resources/imagerecog.gif?raw=true)

è‹¹æœç»™äº†ä¸€ä¸ª MPS çš„ HelloWorldï¼š [MPSCNNHelloWorld: Simple Digit Detection Convolution Neural Networks (CNN)](https://developer.apple.com/library/content/samplecode/MPSCNNHelloWorld/Introduction/Intro.html)ï¼Œæ°å¥½å¯¹åº”ç€æœºå™¨å­¦ä¹ é¢†åŸŸçš„ HelloWorld MNISTã€‚å¯ä»¥é€šè¿‡æŸ¥çœ‹è¿™ä¸ª Demo çš„æºç æ¥å¿«é€Ÿä¸Šæ‰‹ MPS çš„ç”¨æ³•ã€‚

å…¶å®æ€»ä½“æ¥è¯´å¹¶ä¸æ˜¯å¾ˆå¤æ‚ï¼Œä½†æœ‰å‡ ä¸ªé‡è¦çš„åœ°æ–¹éœ€è¦æˆ‘ä»¬è‡ªå·±å»è§£å†³ï¼š

1. æ•°æ®å¤„ç†ï¼Œä¹Ÿå°±æ˜¯æ¨¡å‹æ–‡ä»¶çš„æ•°æ®æ ¼å¼éœ€è¦è‡ªå·±å»è§£æã€‚ä¸åŒæ·±åº¦å­¦ä¹ æ¡†æ¶å¯¼å‡ºçš„æ¨¡å‹æƒé‡æ–‡ä»¶æ ¼å¼éƒ½ä¸ä¸€æ ·ï¼Œä¼šæ¶‰åŠåˆ°æ¯”è¾ƒåº•å±‚çš„ä½è¯»å†™ã€‚è¿™é‡Œæœ‰ä¸€å®šå·¥ä½œé‡ã€‚
2. ä½¿ç”¨å·ç§¯ç¥ç»ç½‘ç»œé¢„æµ‹æ¨¡å‹çš„æ—¶å€™ï¼Œä¼šæ¶‰åŠåˆ° paddingï¼Œè¿™éƒ¨åˆ†éœ€è¦è‡ªå·±è®¡ç®—ã€‚è¾“å‡ºæ•°æ®ä½“åœ¨ç©ºé—´ä¸Šçš„å°ºå¯¸å¯ä»¥é€šè¿‡è¾“å…¥æ•°æ®ä½“å°ºå¯¸ï¼ˆWï¼‰ï¼Œå·ç§¯å±‚ä¸­ç¥ç»å…ƒçš„æ„Ÿå—é‡å°ºå¯¸ï¼ˆFï¼‰ï¼Œæ­¥é•¿ï¼ˆSï¼‰å’Œé›¶å¡«å……çš„æ•°é‡ï¼ˆPï¼‰çš„å‡½æ•°æ¥è®¡ç®—ã€‚è¾“å‡ºæ•°æ®ä½“çš„ç©ºé—´å°ºå¯¸ä¸º (W-F +2P)/S+1ã€‚è¿™é‡Œè¯´çš„æ˜¯æŸä¸ªç»´åº¦ï¼Œå•æŒ‡å®½æˆ–é•¿ã€‚
3. `MPSImage` æ˜¯ä¸ºäº†çªç ´ `MTLTexture` æœ€å¤§ç»´åº¦ä¸º 4 ï¼ˆRGBAï¼‰çš„é™åˆ¶ï¼Œæäº†ä¸ª workaroundï¼Œå°±æ˜¯ç”¨å¤šä¸ªåˆ‡ç‰‡æ¨¡æ‹Ÿå¤šç»´åº¦ã€‚å¦‚æœæœ‰ N ä¸ªç»´åº¦ï¼Œé‚£ä¹ˆåˆ‡ç‰‡æ•°é‡ä¸º (N+3)/4ã€‚æ¯”å¦‚ä¸‹å›¾ä¸º N = 9 çš„æƒ…å†µã€‚æ‰€ä»¥æ¶‰åŠåˆ°æ•°æ®å¯¹é½çš„äº‹æƒ…ï¼Œé¢„æµ‹åçš„æ•°æ®éœ€è¦å¤„ç†ä¸‹ã€‚

	![](https://docs-assets.developer.apple.com/published/48ad0af3fd/b6d1d091-162c-418d-bc2e-0b6f3105c126.png)
	
å¥½åœ¨è‹¹æœæä¾›çš„ Demo é‡Œå·²ç»å¯¹äºåä¸¤ä¸ªé—®é¢˜æœ‰äº†å¯ä»¥å‚è€ƒçš„ä»£ç ï¼Œç¬¬ä¸€ä¸ªé—®é¢˜å…¶å®æ˜¯ä¸ªçŸ©é˜µè½¬æ¢çš„æ“ä½œã€‚ TensorFlow å·ç§¯æ ¸æƒé‡çš„é¡ºåºä¸º [kH kW iC oC]ï¼Œè€Œ MPS æ¥å—çš„æƒé‡ä¸º [oC kH kW iC] å½¢å¼ã€‚è€Œæˆ‘ä½¿ç”¨ Keras çš„æ—¶å€™å°† TensorFlow ä½œä¸ºåç«¯ï¼Œæ‰€ä»¥éœ€è¦è½¬æ¢ä¸‹æƒé‡æ ¼å¼ã€‚çŸ©é˜µè½¬æ¢åœ¨ python é‡Œå¾ˆå®¹æ˜“ï¼Œè¿˜å¥½æˆ‘æ‰¾åˆ°äº† Swift ç‰ˆæœ¬çš„å®ç°ï¼š[SwapAxes](https://github.com/kazoo-kmt/MPSCNNfeeder/blob/master/swapaxes.swift)ï¼Œç›´æ¥æ‹¿è¿‡æ¥ç”¨äº†ã€‚

> PS: ç§‘æ™®ä¸‹ï¼Œ[oC kH kW iC] æ˜¯å››ç»´æ•°ç»„ï¼ˆçŸ©é˜µï¼‰ [outputChannels][kernelHeight][kernelWidth][inputChannels/groups] çš„ shapeã€‚

### ä½¿ç”¨ MPS æ„å»ºç½‘ç»œå¹¶é¢„æµ‹

MPS é¢„æµ‹çš„æ‰§è¡Œæµç¨‹å¦‚ä¸‹ï¼š

1. è·å–å¯ç”¨çš„ device
2. ä» `device` è·å– `commandQueue`ï¼Œä» `commandQueue` è·å– `commandBuffer`
3. æ„å»ºç½‘ç»œæ¨¡å‹å’Œè¾“å…¥æ•°æ®çš„ `MSPImage` å¯¹è±¡
4. è°ƒç”¨ç½‘ç»œæ¯å±‚çš„ `encode` æ–¹æ³•ï¼Œè¾“å…¥ä¸º `commandBuffer` å’Œä¸Šä¸€å±‚ç½‘ç»œè¾“å‡ºçš„ `MSPImage` å¯¹è±¡ã€‚
5. æäº¤ `commandBuffer`
6. ç­‰å¾…è¾“å‡ºç»“æœï¼Œå¹¶å¤„ç†æˆ one-hot æ ¼å¼ã€‚

å‰©ä¸‹çš„å·¥ä½œå°±æ˜¯ä¿®æ”¹å·¥ç¨‹ä¸­çš„ `Inception3Net.swift` æ–‡ä»¶ï¼Œä½¿å…¶ç½‘ç»œç»“æ„ä¸æˆ‘ä»¬ç”¨ Keras æ­å»ºçš„ç½‘ç»œç»“æ„ä¸€æ ·å³å¯ã€‚å‰é¢æåˆ°è¿‡ï¼Œ`Flatten` å’Œ `Dropout` æ²¡æœ‰æƒé‡ï¼Œä¸æ”¹å˜æ•°æ®ã€‚`Flatten` å…¶å®å°±æ˜¯ `reshape` æ“ä½œï¼Œåœ¨ MPS ä¸­ä¸éœ€è¦ç‰¹æ„åš `reshape` æ“ä½œä¹Ÿæ²¡æœ‰ `Flatten` å±‚ï¼Œ`MPSImage` è¢«æè¿°æˆä»€ä¹ˆ shapeï¼Œæ•°æ®å°±ä¼šè¢«æ’åˆ—æˆé‚£ä¸ª shapeã€‚`Dropout` å±‚åœ¨è®­ç»ƒçš„æ—¶å€™æŒ‰ä¸€å®šå‡ ç‡ä¸¢å¼ƒç»“æœï¼Œåœ¨é¢„æµ‹æ¨¡å‹çš„æ—¶å€™æ ¹æœ¬ç”¨ä¸åˆ°ã€‚

å›é¡¾ä¸‹ä¹‹å‰ç”¨ Keras å†™çš„å…¨è¿æ¥å±‚ç»“æ„çš„ä»£ç ï¼š

```
model = Sequential()
model.add(Flatten(input_shape=train_data.shape[1:]))
model.add(Dense(256, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(5, activation='softmax'))
```

è½¬æ¢æˆ MPS çš„ä»£ç åå·®ä¸å¤šæ˜¯è¿™ä¸ªæ ·å­ï¼ˆçœç•¥æ— å…³ä»£ç ï¼‰ï¼š

```
let device = inputCommandQueue.device
let relu = MPSCNNNeuronReLU(device: device!, a: 0)
let softmax = MPSCNNSoftMax(device: device!)
let sftid = MPSImageDescriptor(channelFormat: textureFormat, width: 1  , height: 1  , featureChannels: 5)
// logits
let fc0 = SlimMPSCNNFullyConnected(kernelWidth: 8,
                             kernelHeight: 8,
                             inputFeatureChannels: 2048,
                             outputFeatureChannels: 256,
                             neuronFilter: relu,
                             device: device,
                             kernelParamsBinaryName: "fc1")
   
let fc1 = SlimMPSCNNFullyConnected(kernelWidth: 1,
                             kernelHeight: 1,
                             inputFeatureChannels: 256,
                             outputFeatureChannels: 5,
                             neuronFilter: nil,
                             device: device,
                             kernelParamsBinaryName: "fc2")
...
let image10 = ...
let sftImage    = MPSImage(device: device!, imageDescriptor: sftid)

...

// MPSImageDescriptor for final logits generating layers
let fc0id = MPSImageDescriptor(channelFormat: textureFormat, width: 1, height: 1, featureChannels: 256)
    
var fc0Image, fc1Image : MPSTemporaryImage!
    
func logits_layer(commandBuffer: MTLCommandBuffer){
   // These images are only needed in this layer and will not be read by the CPU or
   // outside of the command bufer, so we can allocate them as MPSTemporaryImages and
   // save the CPU cost and memory size of allocating reserved storage for them.
   //
   // These objects can not be reused outside of the command buffer, which is why
   // we did not make them in the init(withDevice:commandQueue:) call.
   //
   // Temporary images are designed to be efficiently created as needed, used a few times
   // and thrown away almost immediately
   
   fc0Image     = MPSTemporaryImage(commandBuffer: commandBuffer, imageDescriptor: fc0id)
   fc1Image     = MPSTemporaryImage(commandBuffer: commandBuffer, imageDescriptor: sftid)
   
   // encode layers to metal commandBuffer
   fc0.encode    (commandBuffer: commandBuffer, sourceImage: image10, destinationImage: fc0Image)
   fc1.encode    (commandBuffer: commandBuffer, sourceImage: fc0Image, destinationImage: fc1Image)
   softmax.encode(commandBuffer: commandBuffer, sourceImage: fc1Image, destinationImage: sftImage)
   
}
```

## æ€»ç»“

è¿™æ˜¯ä¸€ç¯‡è¡Œå¤–äººçœ‹ä¸æ‡‚ï¼Œè¡Œå†…äººè§‰å¾—æ°´ï¼Œæˆ‘è‡ªå·±è§‰å¾—æ”¶è·æ»¡æ»¡çš„å®è·µç¬”è®°ã€‚å¹¶æ²¡æœ‰èŠ±å¤§é‡ç¯‡å¹…æ€»ç»“Machine Learning çš„åŸºç¡€çŸ¥è¯†ï¼Œä¹Ÿæ²¡æœ‰é€ä¸ªè®²è¿°æ¡†æ¶ API çš„ä½¿ç”¨ï¼Œæ›´æ²¡æœ‰åˆ—ä¸€å †å…¬å¼å’Œæ•°å­¦å®šä¹‰ã€‚ã€‚ã€‚å› ä¸ºè¿™ç§çŸ¥è¯†ä½“ç³»å¤§è€Œå…¨çš„æ–‡ç« ï¼Œç½‘ä¸Šä¸èƒœæšä¸¾ï¼Œè€Œä¸”è‚¯å®šæ¯”æˆ‘æ€»ç»“çš„å¥½ã€‚æœ¬ç€ä¸€ä¸ªå°ç™½å»æ¢ç´¢ä¸–ç•Œçš„å¿ƒæ€ï¼ŒæŠŠè‡ªå·±ä»ç†è®ºå­¦ä¹ åˆ°è®­ç»ƒæ¨¡å‹å†åˆ° iOS ä¸Šçš„é¢„æµ‹çš„å®è·µæµç¨‹è®°å½•ä¸‹æ¥ã€‚å¾ˆå¤šæ¯ç‡¥è€—æ—¶çš„å­¦ä¹  MLã€TF å’Œé…ç½®ç¯å¢ƒçš„è¿‡ç¨‹éƒ½çœç•¥æ‰äº†ã€‚

æœ€åå»ºè®®å¦‚æœæœ‰æ¡ä»¶çš„è¯ï¼Œè¿˜æ˜¯ç”¨é…ç½®è¾ƒé«˜çš„é›†ç¾¤æˆ–è€…äº‘æœåŠ¡æ¥è®­ç»ƒæ¨¡å‹ï¼ŒèŠ‚çœç¨‹åºå‘˜å®è´µçš„æ—¶é—´ã€‚å¦‚æœä¸èƒ½åšåˆ°è‡ªå·±æå‡ºåˆ›æ–°æœ‰æ•ˆçš„ç½‘ç»œæ¨¡å‹ï¼Œå…¶å®æ·±åº¦å­¦ä¹ çš„å¤§é‡å·¥ä½œå°±æ˜¯è°ƒå‚ã€é‡‡é›†æ•°æ®ã€çœ‹åˆ«äººè®ºæ–‡å¦‚ä½•æ”¹å‚æ•°å’Œç½‘ç»œç»“æ„ï¼Œç„¶åç­‰å¾…æœºå™¨è®­ç»ƒç»“æœã€‚ã€‚ã€‚åå¤å¾ªç¯ã€‚ã€‚ã€‚

ç¥ç»ç½‘ç»œä¸æ˜¯çœŸçš„æ¨¡æ‹Ÿå‡ºäººè„‘çš„ç”Ÿç‰©ç‰¹å¾ï¼ŒCNN è·Ÿäººçœ¼æ‰«è§†ä¸–ç•Œæˆ–äººè„‘è¾¨åˆ«ç‰©ä½“å…¶å®å·®å¾ˆå¤šï¼Œæ·±åº¦å­¦ä¹ åªæ˜¯å°½åŠ›è®©æœºå™¨æ‹Ÿåˆå‡ºæƒ³è¦çš„ç»“æœç½¢äº†ï¼Œç¦»çœŸæ­£çš„äººå·¥æ™ºèƒ½è¿˜å·®è¿œäº†ã€‚æ‰€ä»¥ä¸è¦è¢«é“ºå¤©ç›–åœ°çš„å¹å˜˜æ´—è„‘äº†ï¼Œä¸€ä¸ª AlphaGo å°±èƒ½åˆè®©ä¸€å¤§å †æ‰€è°“çš„ç§‘æŠ€åª’ä½“é«˜æ½®å‡ºæœºå™¨å¿«è¦ç»Ÿæ²»äººç±»äº†ï¼Œä¸è¦è€æƒ³æä¸ªå¤§æ–°é—»ï¼

æ·±åº¦å­¦ä¹ å‘å±•å¾ˆå¿«ï¼Œè¦å­¦ä¹ çš„å†…å®¹è¿˜æœ‰å¾ˆå¤šã€‚å­¦ä¹ å¾—è¶Šå¤šï¼Œå°±å‘ç°è‡ªå·±è¶Šæ˜¯æ— çŸ¥ï¼Œä»¥è‡³äºæ€€ç–‘è‡ªå·±çš„æ™ºå•†å’Œç²¾åŠ›äº†ã€‚

## Reference

[Coursera Machine Learning](https://www.coursera.org/learn/machine-learning/home)
[TensorFlow](https://www.tensorflow.org)
[Keras ä¸­æ–‡æ–‡æ¡£](http://keras-cn.readthedocs.io/en/latest/)
[Keras Documentation](https://keras.io)
[ImageNet](http://image-net.org)
[kaggle](https://www.kaggle.com)
[CS231n: Convolutional Neural Networks for Visual Recognition](http://cs231n.stanford.edu)
[Convolutional Neural Networks (CNNs / ConvNets)](http://cs231n.github.io/convolutional-networks/)
[Convolutional neural networks on the iPhone with VGGNet](http://machinethink.net/blog/convolutional-neural-networks-on-the-iphone-with-vggnet/)
[Building powerful image classification models using very little data](https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html)
[HDF Group](https://www.hdfgroup.org)
[MetalPerformanceShaders](https://developer.apple.com/reference/metalperformanceshaders)
[BNNS](https://developer.apple.com/reference/accelerate/bnns)
[HDF5Kit](https://github.com/aleph7/HDF5Kit)
[iOS-10-Sampler](https://github.com/shu223/iOS-10-Sampler)
[MPSCNNfeeder](https://github.com/kazoo-kmt/MPSCNNfeeder)

